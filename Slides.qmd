---
title: "Linear Mixed-Effects Models"
author: "Nick Freeland, Bernice Green, Gary Marmon"
format:
  revealjs: 
    theme: league
    preview-links: auto
---

# Introduction

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
#| warning: false
#| message: false
#| include: false

# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
library(nflverse)
library(nflplotR)
library(kableExtra)
library(GLMsData)
library(ggfortify)
library(gridExtra)
library(lme4)
library(lmerTest)

# loading play by play data from the 2021 NFL season
pbp <- nflreadr::load_pbp(2021)

# team summaries 
team_sum1 <- data.frame(pbp$game_id, pbp$home_coach, pbp$away_coach, pbp$posteam, pbp$posteam_type, pbp$pass, pbp$rush, pbp$epa, pbp$down, pbp$week, pbp$season_type, pbp$yards_gained, pbp$shotgun, pbp$no_huddle, pbp$yards_after_catch)

team_sum2 <- team_sum1 %>%
  filter(pbp.rush == 1 | pbp.pass == 1, !is.na(pbp.down)) %>%
  group_by (pbp.posteam, pbp.posteam_type, pbp.game_id) %>%
  mutate(coach = ifelse(pbp.posteam_type == 'home',pbp.home_coach,pbp.away_coach)) %>%
  mutate(opp_coach = ifelse(pbp.posteam_type == 'away',pbp.home_coach,pbp.away_coach)) %>%
  mutate(home_adv = ifelse(pbp.posteam_type == 'home', 0, 1))%>%
  summarize(week = first(pbp.week),
            season_type = first(ifelse(pbp.season_type == 'REG', 0, 1)),
            home_adv = first(home_adv),
            coach = first(coach),
            opp_coach = first(opp_coach),
            plays = n(),
            pass_plays = sum(pbp.pass),
            pass_pct = pass_plays / plays,
            yards_gained = sum(pbp.yards_gained),
            shotgun_snaps = sum(pbp.shotgun),
            no_huddle_snap = sum(pbp.no_huddle),
            epa_per_play = round(mean(pbp.epa), digits = 2))

```

## Simple Linear Regressions

-   assumes independence of observations

-   slopes and intercepts measure average trends

```{r Linear Regression, echo=FALSE, message=FALSE, warning=FALSE}
x <- c(9,9,7,8,7,8,4,5,5,4,6,2,1,3,3,2,1,2,1,0,2,8,10,9,7.5,6,10)
y <- c(0,1,0,2,2,1,3,4,5,4,6,5,5,6,8,7,7,8,9,9,9,5,3,4,0,0,4)
z <- c('A','A','A','A','A','A','B','B','B','B','B','B','B','B','C','C','C','C','C','C','C','A','A','A','A','A','A')


data <- data.frame(x,y,z)

slr <- ggplot(data, aes(x, y)) + 
    geom_point(size=4) + # change size and colour
   scale_y_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) + # y axis limits/range (0, 100), break points
    scale_x_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) + # x axis limits/range 
    geom_smooth(method = 'lm', se = F) # fit linear regression line

slr
```

# But...

What if the observations are not independent?

What if trends vary between clusters?

```{r message=FALSE, warning=FALSE}
slr.col <- ggplot(data, aes(x, y, col = z)) + 
    geom_point(size=4) + # change size and colour
    scale_y_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) + # y axis limits/range (0, 100), break points
    scale_x_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) + # x axis limits/range 
    geom_smooth(method = 'lm', se = F, aes(group = 1)) # fit linear regression line

slr.col
```

## Linear Mixed-Effects Models (LMMs)

-   LMMs can be used to model correlated data
    -   Cross sectional data: individuals nested in a geographical or social context - *ex: Student test data compared across Geometry classes*

    -   Longitudinal data: repeated measures of individuals - *ex: Student test data over time*

Main application for mixed-effect models is in psychology due to the nature of their data and repeated observations across trial participants

```{r message=FALSE, warning=FALSE}
lmm <- ggplot(data, aes(x, y, col = z)) + 
    geom_point(size=4) + # change size and colour
    scale_y_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) + # y axis limits/range (0, 100), break points
    scale_x_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) + # x axis limits/range 
    geom_smooth(method = 'lm', se = F)  # fit linear regression line

lmm
```

## Fixed vs. Random Effects

-Fixed Effects 
  -   show average trends for the population
  -   assume constant relationship between response and exploratory features
  -   infer/predict about levels included in the training data

. . .

-Random Effects 
  -   show how trends vary across groups
  -   assumes constant relationship between response and exploratory features but relationship may vary between groups
  -   infer/predict about all levels in the population

## Fixed and Random Effects

-   mixed-effects models simultaneously model fixed and random effects

-   fixed effect parameters

    -   small number of clusters, large number of observations

-   random effect parameters

    -   large number of clusters, small number of clusters per observation

**It's important to include the random effects in the model since fixed effects only give a partial picture of hierarchical data.**

## Linear Model vs Linear Mixed-Effects Model

```{r message=FALSE, warning=FALSE}
slr.lmm <- ggplot(data, aes(x, y, col = z)) + 
    geom_point(size=4) + # change size and colour
    scale_y_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) + # y axis limits/range (0, 100), break points
    scale_x_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) + # x axis limits/range 
    geom_smooth(method = 'lm', se = F) + # fit linear regression line
    geom_smooth(method = 'lm', se = F, aes(group = 1)) # fit linear regression line

slr.lmm
```

## Overview
Until more recently the only way to handle the type of data mixed-effects model does was through repeated measures ANOVAs. Mixed-effects models are much more versatile in handling variability within and across groups and can handle missing data, providing much better results than the ANOVAs. [@brown2021introduction]

- Mixed-effects models more versatile with missing data and generally better predictions

## Applications
The main application for mixed-effect models is in psychology due to the nature of their data and repeated observations across trial participants. However, the applications can extend into almost any field where the variability across a group/person is desired in the analysis. One such example is the use of mixed-effects models on published health data sets to explore the link between smoking and depression in which it was found “Smoking status is robustly associated with depression (or depressive symptomatology) at 1 ½ to 2 times the risk of nonsmoking across a variety of study designs, depression measurements, and participant populations” [@luger2014robust].

- Mixed effects models: regression with variability across groups

## Distribution Assumptions: {.scrollable} 

Just as a linear model is described by the distribution of a vector-valued random response variable, Y, whose observed value is $y_{obs}$, a linear mixed model is described by the distribution of two vector-valued random variables: $Y$, the response, and $\beta$, the vector of random effects. In a linear model the distribution of Y is multivariate normal, $$ Y ∼ N(Xβ + o, σ^2 W^{-1}) $$

## Assumption Violations: {.scrollable}
The complex nature of mixed-effects models call into question the robustness of these models and brings more focus to the model assumptions. "Mixed-effects models involve complex fitting procedures and make several assumptions, in particular about the distribution of residual and random effects. Violations of these assumptions are common in real datasets, yet it is not always clear how much these violations matter to accurate and unbiased estimation." (Schielzeth et al. 2020). The study found mixed-effects models to be very robust to violations of these assumptions, finding the estimates were unbiased and missing random effect predictors had little effect on the fixed effect estimates but had some effects on the estimates of random effects.

- Mixed-effects models offer good prediction even if assumptions on distribution are violated

# Methods and Data

## Predicting coach preformace:
Our basic model: $$epa = plays +  (1+plays|coach)$$

- Parentheses indicate variable slopes and intercepts
- Other variables for consideration: pass_pct, yards_gained, no_huddle_snap, shotgun_snaps, home_adv

## The Data: {.scrollable} 

Our data featured a play by play analysis for every game in the 2021 season.

| Variable         | Meaning                                                                 |
|:--------------------|:--------------------------------------------------|
| pbp.posteam      | the team with possession of the ball (offense)                          |
| pbp.posteam_type | specifies if the possessing team is home or away                        |
| pbp.game_id      | the specific game id from the NFL                                       |
| week             | week number in the season that the game was played                      |
| season_type      | flag that specifies if it is a regular (0) or post (1) season game      |
| home_adv         | flag that specifies home (0) or away(1)                                 |
| coach            | the coach of the team with possession (offensive plays)                 |
| opp_coach        | the coach of the opposing team (defensive plays)                        |
| plays            | total number of rush and pass plays given the team and game             |
| pass_plays       | number of pass plays given the team and game                            |
| pass_pct         | the percentage of pass plays in the game calculated by pass_plays/plays |
| yards_gained     | yards gained by an offense                                              |
| shotgun_snaps    | number of snaps a team lined up in a shotgun formation                  |
| ho_huddle_snaps  | number of snaps a team used a no huddle offense                         |
| EPA_per_play     | the mean of all pass and rush plays given team and game                 |

------------------------------------------------------------------------

## EPA per Play by Coach:

```{r, warning=FALSE, echo=TRUE}
# Compare EPA by coach
ggplot(team_sum2, aes(epa_per_play)) +
  geom_boxplot() +
  facet_wrap(~ coach) +
  theme_minimal()
  
```

## Team Epa Performance: 
```{r message=FALSE, warning=FALSE}
offense <- pbp %>%
  dplyr::group_by(team = posteam) %>%
  dplyr::summarise(off_epa = mean(epa, na.rm = TRUE))
defense <- pbp %>%
  dplyr::group_by(team = defteam) %>%
  dplyr::summarise(def_epa = mean(epa, na.rm = TRUE))
offense %>%
  dplyr::inner_join(defense, by = "team") %>%
  ggplot2::ggplot(aes(x = off_epa, y = def_epa)) +
  ggplot2::geom_abline(slope = -1.5, intercept = c(.4, .3, .2, .1, 0, -.1, -.2, -.3), alpha = .2) +
  nflplotR::geom_mean_lines(aes(h_var = off_epa, v_var = def_epa)) +
  nflplotR::geom_nfl_logos(aes(team_abbr = team), width = 0.07, alpha = 0.7) +
  ggplot2::labs(
    x = "Offense EPA/play",
    y = "Defense EPA/play",
    title = "2021 NFL Offensive and Defensive EPA per Play"
  ) +
  ggplot2::theme_bw() +
  ggplot2::theme(
    plot.title = ggplot2::element_text(size = 12, hjust = 0.5, face = "bold")
  ) +
  ggplot2::scale_y_reverse()
```

## Plays:
```{r}
ggplot(team_sum2, aes(x=plays, y=epa_per_play, color=coach)) + geom_point()
```

## Pass Pct:
```{r}
ggplot(team_sum2, aes(x=pass_pct, y=epa_per_play, color=coach)) + geom_point()
```

## Yards Gained:
```{r message=FALSE, warning=FALSE}
team_sum2 |>
  ggplot(aes(y=epa_per_play, x=yards_gained)) + 
  geom_smooth(method = "loess")
```

## Shotgun Snaps:
```{r message=FALSE, warning=FALSE}
team_sum2 |>
  ggplot(aes(y=epa_per_play, x=shotgun_snaps)) + 
  geom_smooth(method = "loess")
```

## No Huddle:
```{r message=FALSE, warning=FALSE}
team_sum2 |>
  ggplot(aes(y=epa_per_play, x=no_huddle_snap)) + 
  geom_smooth(method = "loess")
```

## Starting with a simple linear model {.smaller}

```{r}
#| include: true
#| echo: true
#| warning: false
#| message: false
epa.lm = lm(epa_per_play ~ pass_pct + plays + yards_gained + shotgun_snaps + no_huddle_snap, 
            data=team_sum2)
summary(epa.lm)
```

- After accounting for the other variables, the number of shotgun snaps an offense runs does not appear to significantly effect epa per play
- Current model explains approximately 63% of the variance in epa per play. 

## Diagnostics

```{r}
#| include: true
#| echo: true
#| warning: false
#| message: false
autoplot(epa.lm)
```

- a few outliers are present, but the overall fit looks acceptable.
- we will move forward with a linear approach

## Linear Mixed Effects Model {.smaller}

- We want to account for a teams coach and if a team has home field advantage as random effects. 

```{r}
#| include: true
#| echo: true
#| warning: false
#| message: false

# LMM - random intercepts
epa.lmer1 = lmer(epa_per_play ~ pass_pct + plays + yards_gained + no_huddle_snap + 
                (1|coach) + (1|home_adv), data=team_sum2)

epa.lmer1
```
## Interpreting the Random Effects {.smaller}

```{r}
#| include: true
#| echo: true
#| warning: false
#| message: false
#| 
epa.lmer1
```


- we observe the home advantage random effect approaches zero, concluding there is no additional change in epa per play due to home field advantage itself. 

- we observe an additional 0.02 epa per play due to coaching  


## Random Intercept Model {.smaller}

```{r}
#| include: true
#| echo: true
#| warning: false
#| message: false
coef(epa.lmer1)
```
- Each coach is assigned a different intercept, but the fixed effects are the same for all coaches. 
- This model is called a Random Intercept model; we are accounting for baseline differences in epa per play. 

## Random Slope Model {.smaller}

```{r}
#| include: true
#| echo: true
#| warning: false
#| message: false

# LMM - random slopes
epa.lmer2 = lmer(epa_per_play ~ pass_pct + plays + yards_gained + shotgun_snaps + no_huddle_snap +
                (1+pass_pct|coach) + (1+plays|coach) + (1+yards_gained|coach) + (1+shotgun_snaps|coach) + (1+no_huddle_snap|coach), data=team_sum2)
```

- Alternatively, in a Random Slope model, each coach is allowed to have a different intercept, as well as different slopes for the effect of number of plays ran and percentage of pass plays, etc.

## Interpretation {.smaller}

```{r}
#| include: true
#| echo: true
#| warning: false
#| message: false
coef(epa.lmer2)
```


- Despite the individual variation of pass_pct, all the values are negative and very close to each other. 
- We see consistency with how often coaches throw the ball. 
- The variation in number of shotgun snaps an offense runs is much wider.


## Testing for Significance Between Models {.smaller}

```{r}
#| include: true
#| echo: true
#| warning: false
#| message: false

# Testing for significance between models with and without home field advantage
epa.lmer2.null = lmer(epa_per_play ~ pass_pct + plays + yards_gained + shotgun_snaps + no_huddle_snap +
                  (1+pass_pct|coach) + (1+plays|coach) + (1+yards_gained|coach) + (1+shotgun_snaps|coach) + (1+no_huddle_snap|coach),                                            data=team_sum2,
                  REML=FALSE)

epa.lmer2.full = lmer(epa_per_play ~ home_adv + pass_pct + plays + yards_gained + shotgun_snaps + no_huddle_snap +
                  (1+home_adv|coach) + (1+pass_pct|coach) + (1+plays|coach) + (1+yards_gained|coach) + (1+shotgun_snaps|coach) + (1+no_huddle_snap|coach),                       data=team_sum2,
                  REML=FALSE)

anova(epa.lmer2.full, epa.lmer2.null)

```

- no statistical significance between the models -the effect of home field advantage is minimal to zero

## Conclusion {.smaller}

Using a mixed-effects approach we are able to find the additional effect a subject (a team's coach in our case) has on a offenses success, measured by epa per play. After accounting for the fixed effects plays ran, percentage of pass plays, yards gained, shotgun snaps, and no huddle snaps, our random effect coefficient for coaching showed an additional change 0.02 epa per play due to coaching and no change in epa per play due to home field advantage.
